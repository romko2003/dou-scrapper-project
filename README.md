# Python Technologies Statistics (DOU.ua)

This project combines **Web Scraping** and **Data Analysis** to analyze the most in-demand technologies in Python job vacancies on **dou.ua**.

The goal is to help Python developers understand which technologies are currently most required on the job market, so they can prioritize what to learn and prepare better for interviews.

---

## ğŸš€ Project Overview

The project:
- Scrapes public Python job vacancies from dou.ua  
- Extracts technologies mentioned in job descriptions  
- Counts how frequently each technology appears  
- Visualizes popularity statistics using charts  
- Stores historical results to track trends over time  

---

## ğŸ§± Project Architecture

The project is split into **two independent parts** (Single Responsibility Principle):

### 1ï¸âƒ£ Scraping Module
- Collects vacancy links
- Downloads job descriptions
- Saves raw vacancy data into JSON

### 2ï¸âƒ£ Data Analysis Module
- Loads stored vacancy data
- Analyzes technology mentions
- Builds statistics & charts
- Saves visualization results

---

## ğŸ›  Technologies Used

- Python  
- Requests  
- BeautifulSoup  
- Pandas  
- Matplotlib  
- SQLite (optional storage)  
- Asyncio (optional performance upgrade)  
- NLP tools (optional: nltk, wordcloud)  

---

## ğŸ“Š Example Output

The project generates charts showing the **most demanded technologies**:

![Technology Popularity Chart](charts/tech_popularity.png)

---

## âš™ï¸ How to Run the Project

### 1. Clone the repository
```bash
git clone https://github.com/YOUR_USERNAME/py-dou-tech-stats.git
cd py-dou-tech-stats
2. Install dependencies
pip install -r requirements.txt
3. Run the scraper & analysis
python main.py
ğŸ“ Project Structure
py-dou-tech-stats/
â”‚
â”œâ”€â”€ scraper/           # Scraping logic
â”œâ”€â”€ analysis/          # Data processing & charts
â”œâ”€â”€ data/              # Raw scraped vacancies
â”œâ”€â”€ charts/            # Generated visualizations
â”œâ”€â”€ config.py          # Technology list & settings
â”œâ”€â”€ main.py            # Project entry point
â””â”€â”€ README.md
ğŸ“Œ Configuration
You can modify tracked technologies in config.py:

TECHNOLOGIES = [
    "Python", "Django", "Flask", "FastAPI",
    "PostgreSQL", "Docker", "AWS",
    "Redis", "Celery", "Pandas"
]
ğŸ“ˆ Additional Features (Optional Enhancements)
Async scraping for performance

NLP-based technology extraction (no static config)

WordCloud visualization

Experience level segmentation (Junior / Middle / Senior)

Market trend tracking over time

Salary & popularity correlation analysis

âš ï¸ Disclaimer
Only public job data is scraped

No authentication is used

No private user data is collected

Scraping respects legal and ethical standards

ğŸ‘¨â€ğŸ’» Author
Roman Azhniuk
Mate Academy â€” Python Track

â­ Why This Project Matters
This project helps developers:

Understand real job market demand

Make informed learning decisions

Build strong portfolio projects

Gain real-world scraping & analytics experience
